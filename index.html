<html>

<head>
  <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" />
  <meta http-equiv="Pragma" content="no-cache" />
  <meta http-equiv="Expires" content="0" />

  <title>Bryan Russell</title>

  <style TYPE="text/css">
  body,table {font-family:helvetica; font-size:1.1em;}
  //body {width:53em; margin-left:1.5em;}

  #wrap { 
    width: 65em; 
    margin: 0 auto; 
  }

  a:link {
    color: #4174a0;
    text-decoration: underline;}
  a:visited {
    color: #4174a0;
    text-decoration: underline;}
  a:hover {
    color: #555555;
    text-decoration: underline;}
  </style>
</head>

<body>

<div id="wrap">

  <table width="100%" cellpadding="0" cellspacing="0">
    <tr>
      <td style="align:left; vertical-align:top;">
          <font style="font-size:2.7em;">
          Bryan Russell
	  </font>
          <br />

	  <br />
          <font style="font-size:1em;">
	  Lead, Video Understanding Group
	  <br />Senior Research Scientist
	  <br /><a style="text-decoration:none;"
	  href="https://research.adobe.com/">Adobe
	  Research</a>
	  </font>
	  <br />
	  <br />Mailing address: 601 Townsend Street, San Francisco, CA 94103
	  <br />E-mail: brussell at adobe.com
	  <br />
	  <br /><a href="http://scholar.google.com/citations?user=3RuMCpcAAAAJ"><img src="thumbs/google_scholar_thumb.png" style="height:2em;" /></a>
	  <a href="https://www.linkedin.com/in/bryan-russell-6764b3a/"><img src="thumbs/linkedin_thumb.png" style="height:2em;" /></a>
      </td>

      <td style="vertical-align:top;" align="right">
          <img src="me10_small.jpg" style="border: 1px solid #979797; height:14em;" border="0" alt="Bryan Russell" />
      </td>
    </tr>
  </table>
  
<br />

<p>
<b>Internships:</b>
I recruit enthusiastic and talented Ph.D., master's, and advanced undergraduate students in computer science for summer internships at Adobe in San Francisco. Applications are reviewed between November and February. Please note that intern positions are limited and highly competitive. To apply, email me your CV and a brief description of your desired internship project.
</p>

<p>
<b>Research</b>: 
My current research focuses on developing models and algorithms that enable video search, editing, and understanding for generative AI. This multidisciplinary work encompass computer vision, machine learning, computer graphics, and audio research.
<!--
My research is in computer vision, machine learning, and computer graphics.  I'm interested in the
following areas:
<ul>
<li><b>Learning from video:</b> How can we learn a good representation of video via (cross-modal) self supervision? How can we best jointly model natural language, audio, and video? Potential applications include large-scale search and retrieval for video and smart video editing.
<li><b>3D scene understanding:</b> How can we recover a good (editable and controllable) representation of a depicted 3D scene from one or more images? How can we learn real-world physics from video? How can we learn from real-world interactions in an environment? Potential applications include augmented reality, 2D-3D compositing and editing, and robotics.
</ul>
-->
</p>

  <p>
<b>Bio</b>:
I received my Ph.D. from <a href="http://mit.edu">MIT</a> in the <a href="http://www.csail.mit.edu">Computer Science and Artificial
Intelligence Laboratory</a> under the supervision of Professors
<a href="http://people.csail.mit.edu/billf/">Bill Freeman</a> and
<a href="http://web.mit.edu/torralba/www/">Antonio Torralba</a>.
I was a post-doctoral fellow in the INRIA <a href="http://www.di.ens.fr/willow/">Willow team</a>
at the <a href="http://www.di.ens.fr/">D&eacute;partement d'Informatique</a> of <a href="http://www.ens.fr/">Ecole Normale Sup&eacute;rieure</a>.
Before joining Adobe, I was a Research Scientist with Intel Labs as part of
the <a href="http://visual.stanford.edu/">Intel Science and Technology
  Center for Visual Computing</a> (ISTC-VC) and Affiliate Faculty
at the <a href="http://www.cs.washington.edu">University of Washington</a>. (<a href="talk_bio.html">Talk bio</a>)
</p>

<p>
<b>Professional activities</b>: 

<ul>
<li>Area chair: CVPR 2016, 3DV 2016, ECCV 2018, CVPR 2019, CVPR 2020, ECCV 2020, CVPR 2023, NeurIPS 2023, ECCV 2024, CVPR 2025, CVPR 2026.
<li>DEI chair: ECCV 2022.
</ul>

  <hr />

<b>Tech transfers:</b>

<ul>
<li>Media Intelligence (visual search) in Adobe Premiere Pro (<a href="https://news.adobe.com/news/2025/04/new-ai-innovation-in-industry">Adobe announcement</a>)
<li>Camera controls in the Adobe Firefly Video Model (<a href="https://blog.adobe.com/en/publish/2024/09/11/bringing-gen-ai-to-video-adobe-firefly-video-model-coming-soon">Adobe blog post</a>)
<li>Video shot size and angle filter in Adobe Stock (<a href="https://blog.adobe.com/en/publish/2021/10/26/whats-new-adobe-stock-2021">Adobe MAX 2021 announcement</a>)
<li>Video smart tags in Adobe Experience Manager (<a href="https://experienceleague.adobe.com/docs/experience-manager-cloud-service/assets/manage/smart-tags-video-assets.html?lang=en#video-smart-tags">feature description</a> and <a href="https://experienceleague.adobe.com/docs/experience-manager-cloud-service/release-notes/release-notes/2020/release-notes-2020-10-0.html?lang=en#what-is-new-sites">release notes</a>)
<li>Video auto-tagging in Adobe Experience Manager UGC (<a href="https://medium.com/adobetech/how-adobes-enhanced-smart-tags-capability-empowers-marketers-to-find-the-most-relevant-ugc-video-44a50f3ba6c2">blog post</a>) 
<li>Auto-ground plane in Adobe Dimension (<a href="https://theblog.adobe.com/labs-to-features-auto-ground-plane-in-project-felix/">blog post</a>)
<li>Automatic portrait segmentation in Adobe Photoshop Mix mobile app's "auto cut out" feature (<a href="https://www.youtube.com/watch?v=DQ8va2ipK8I">demo video</a>)
</ul>


<hr />

<b>Selected projects (</b><a href="publications.html">complete list of publications</a><b>):</b>

  <font style="font-size:0.9em;">

  <table style="border-spacing:0em 2em;">

<!-- template
  <tr>
  <td>
  <a href="XXX"><img src="thumbs/XXX" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="XXX">Paper title</a>
  <br />Authors
  <br />Conference, Year.
  </td>
  </tr>
-->

  <tr>
  <td>
  <a href="https://lisadunlap.github.io/CompCon-Website/"><img src="thumbs/2025_iccv_compcon_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://lisadunlap.github.io/CompCon-Website/">Discovering Divergent Representations between Text-to-Image Models</a>
  <br />Lisa Dunlap, Joseph E. Gonzalez, Trevor Darrell, Fabian Caba Heilbron, Josef Sivic, Bryan Russell
  <br />International Conference on Computer Vision (ICCV), 2025.
  </td>
  </tr>


  <tr>
  <td>
  <a href="https://soldelli.github.io/residualvit/"><img src="thumbs/2025_iccv_residualvit_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://soldelli.github.io/residualvit/">ResidualViT for Efficient Temporally Dense Video Encoding</a>
  <br />Mattia Soldan, Fabian Caba Heilbron, Bernard Ghanem, Josef Sivic, Bryan Russell
  <br />International Conference on Computer Vision (ICCV), 2025.
  </td>
  </tr>


  <tr>
  <td>
  <a href="https://mudtriangle.com/editduet/"><img src="thumbs/2025_siggraph_editduet_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://mudtriangle.com/editduet/">EditDuet: A Multi-Agent System for Video Non-Linear Editing</a>
  <br />Marcelo Sandoval-Casta&ntilde;eda, Bryan Russell, Josef Sivic, Gregory Shakhnarovich, Fabian Caba Heilbron
  <br />SIGGRAPH, 2025.
  </td>
  </tr>


  <tr>
  <td>
  <a href="https://github.com/adobe-research/polar-vl"><img src="thumbs/2025_cvpr_polar_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td> 
  <a href="https://github.com/adobe-research/polar-vl">Improving Personalized Search with Regularized Low-Rank Parameter Updates</a>
  <br />Fiona Ryan, Josef Sivic, Fabian Caba Heilbron, Judy Hoffman, James M. Rehg, Bryan Russell
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2025.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://ificl.github.io/MultiFoley/"><img src="thumbs/2025_cvpr_multifoley_thumb.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td> 
  <a href="https://ificl.github.io/MultiFoley/">Video-Guided Foley Sound Generation with Multimodal Controls</a>
  <br />Ziyang Chen, Prem Seetharaman, Bryan Russell, Oriol Nieto, David Bourgin, Andrew Owens, Justin Salamon
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2025.
  </td>
  </tr>

  <tr>
  <td>
<div>
<a href="https://joaanna.github.io/customizing_motion/">
<video autoplay loop muted playslinline width="40%">
<source src="thumbs/2024_accv_custom_thumb.mp4" type="video/mp4">
</video>
</a>
<br />
<div style="font-family: 'Comic Sans MS', 'Comic Sans', cursive; font-style: italic; font-size:0.75em;">Nurses dancing the <span style="color:blue;">V* dance</span> in a hospital</div>
</div>
&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://joaanna.github.io/customizing_motion/">NewMove: Customizing Text-to-Video Models with Novel Motions</a>
  <br />Joanna Materzy&nacute;ska, Josef Sivic, Eli Shechtman, Antonio Torralba, Richard Zhang, Bryan Russell
  <br />Asian Conference on Computer Vision (ACCV), 2024.
  </td>
  </tr>


  <tr>
  <td>
  <a href="https://cs-people.bu.edu/rxtan/projects/Koala/"><img src="thumbs/2024_cvpr_koala_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://cs-people.bu.edu/rxtan/projects/Koala/">Koala: Keyframe-Conditioned Long Video-LLM</a>
  <br />Reuben Tan, Ximeng Sun, Ping Hu, Jui-hsien Wang, Hanieh Deilamsalehy, Bryan A. Plummer, Bryan Russell, Kate Saenko
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2024.
  </td>
  </tr>


  <tr>
  <td>
  <a href="https://www.danielbmckee.com/language-guided-music-for-video/"><img src="thumbs/2023_cvpr_viml_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://www.danielbmckee.com/language-guided-music-for-video/">Language-Guided Music Recommendation for Video via Prompt Analogies</a>
  <br />Daniel McKee, Justin Salamon, Josef Sivic, Bryan Russell
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2023.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://xypb.github.io/CondFoleyGen/"><img src="thumbs/2023_cvpr_avanalogies_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://xypb.github.io/CondFoleyGen/">Conditional Generation of Audio from Video via Foley Analogies</a>
  <br />Yuexi Du, Ziyang Chen, Justin Salamon, Bryan Russell, Andrew Owens
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2023.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://cs-people.bu.edu/rxtan/projects/VAST/"><img src="thumbs/2023_cvpr_sourceseparation_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://cs-people.bu.edu/rxtan/projects/VAST/">Language-Guided Audio-Visual Source Separation via Trimodal Consistency</a>
  <br />Reuben Tan, Arijit Ray, Andrea Burns, Bryan A. Plummer, Justin Salamon, Oriol Nieto, Bryan Russell, Kate Saenko
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2023.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://danielchyeh.github.io/metaper/"><img src="thumbs/2023_cvpr_metapersonal_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://danielchyeh.github.io/metaper/">Meta-Personalizing Vision-Language Models to Find Named Instances in Video</a>
  <br />Chun-Hsiao Yeh, Bryan Russell, Josef Sivic, Fabian Caba Heilbron, Simon Jenni
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2023.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://hangg7.com/dycheck">
<video autoplay loop muted playslinline width="50%">
<source src="thumbs/2022_neurips_dycheck_thumb.mp4" type="video/mp4">
</video>
</a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://hangg7.com/dycheck">Monocular Dynamic View Synthesis: A Reality Check</a>
  <br />Hang Gao, Ruilong Li, Shubham Tulsiani, Bryan Russell, Angjoo Kanazawa
  <br />Advances in Neural Information Processing Systems (NeurIPS), 2022.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://musicforvideo.cs.columbia.edu/"><img src="thumbs/2022_cvpr_mvpt_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://musicforvideo.cs.columbia.edu/">It's Time for Artistic Correspondence in Music and Video</a>
  <br />D&iacute;dac Sur&iacute;s, Carl Vondrick, Bryan Russell, Justin Salamon
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2022.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://jason718.github.io/nvos/"><img src="thumbs/2022_cvpr_nvos_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://jason718.github.io/nvos/">Neural Volumetric Object Selection</a>
  <br />Zhongzheng Ren, Aseem Agarwala, Bryan Russell, Alexander G. Schwing, Oliver Wang
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2022.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://ponimatkin.github.io/focalpose/index.html"><img src="thumbs/2022_cvpr_focalpose_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://ponimatkin.github.io/focalpose/index.html">Focal Length and Object Pose Estimation via Render and Compare</a>
  <br />Georgy Ponimatkin, Yann Labb&eacute;, Bryan Russell, Mathieu Aubry, Josef Sivic

  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2022.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://cs-people.bu.edu/rxtan/projects/grounding_narrations"><img src="thumbs/2021_neurips_localize_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://cs-people.bu.edu/rxtan/projects/grounding_narrations">Look at What I'm Doing: Self-Supervised Spatial Grounding of Narrations in Instructional Videos</a>
  <br />Reuben Tan, Bryan A. Plummer, Kate Saenko, Hailin Jin, Bryan Russell
  <br />Advances in Neural Information Processing Systems (NeurIPS), 2021.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://shuangli-project.github.io/weakly-supervised-human-object-detection-video"><img src="thumbs/2021_iccv_hoi-video_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://shuangli-project.github.io/weakly-supervised-human-object-detection-video">Weakly Supervised Human-Object Interaction Detection in Video via Contrastive Spatiotemporal Regions</a>
  <br />Shuang Li, Yilun Du, Antonio Torralba, Josef Sivic, Bryan Russell
  <br />International Conference on Computer Vision (ICCV), 2021.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://editnerf.csail.mit.edu"><img src="thumbs/2021_iccv_editnerf_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://editnerf.csail.mit.edu">Editing Conditional Radiance Fields</a>
  <br />Steven Liu, Xiuming Zhang, Zhoutong Zhang, Richard Zhang, Jun-Yan Zhu, Bryan Russell
  <br />International Conference on Computer Vision (ICCV), 2021.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://geometry.stanford.edu/projects/human-dynamics-eccv-2020/"><img src="thumbs/2020_eccv_contact_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://geometry.stanford.edu/projects/human-dynamics-eccv-2020/">Contact and Human Dynamics from Monocular Video</a>
  <br />Davis Rempe, Leonidas J. Guibas, Aaron Hertzmann, Bryan Russell, Ruben Villegas, Jimei Yang
  <br />European Conference on Computer Vision (ECCV), 2020.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://karreny.github.io/telling-left-from-right/"><img src="thumbs/2020_cvpr_asmr_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://karreny.github.io/telling-left-from-right/">Telling Left from Right: Learning Spatial Correspondence of Sight and Sound</a>
  <br />Karren Yang, Bryan Russell, Justin Salamon
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2020.
  <br /><a href="https://research.adobe.com/news/teaching-machines-to-understand-and-generate-3d-sound-with-asmr-videos/">Adobe blog</a>
  </td>
  </tr>
  
  <tr>
  <td>
  <a href="http://imagine.enpc.fr/~deprellt/atlasnet2/"><img src="thumbs/2019_neurips_thumb.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://imagine.enpc.fr/~deprellt/atlasnet2/">Learning Elementary Structures for 3D Shape Generation and Matching</a>
  <br />Theo Deprelle, Thibault Groueix, Matthew Fisher, Vladimir G. Kim, Bryan Russell, Mathieu Aubry
  <br />Advances in Neural Information Processing Systems (NeurIPS), 2019.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://geometry.cs.ucl.ac.uk/projects/2019/bounce-neural-resim/"><img src="thumbs/2019_iccv_bounce_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://geometry.cs.ucl.ac.uk/projects/2019/bounce-neural-resim/">Neural Re-Simulation for Generating Bounces in Single Images</a>
  <br />Carlo Innamorati, Bryan Russell, Danny M. Kaufman, Niloy J. Mitra
  <br />International Conference on Computer Vision (ICCV), 2019.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://lmb.informatik.uni-freiburg.de/projects/freihand/"><img src="thumbs/2019_iccv_hand_thumb.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://lmb.informatik.uni-freiburg.de/projects/freihand/">FreiHAND: A Dataset for Markerless Capture of Hand Pose and Shape from Single RGB Images</a>
  <br />Christian Zimmermann, Duygu Ceylan, Jimei Yang, Bryan Russell, Max Argus, Thomas Brox
  <br />International Conference on Computer Vision (ICCV), 2019.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://imagine.enpc.fr/~groueixt/sgp/index.html"><img src="thumbs/2019_sgp_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://imagine.enpc.fr/~groueixt/sgp/index.html">Unsupervised Cycle-Consistent Deformation for Shape Matching</a>
  <br />Thibault Groueix, Matthew Fisher, Vladimir G. Kim, Bryan Russell, Mathieu Aubry
  <br />Symposium on Geometry Processing (SGP), 2019.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://www.cs.cmu.edu/~spurushw/publication/bouncelearn"><img src="thumbs/2019_bounce_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://www.cs.cmu.edu/~spurushw/publication/bouncelearn">Bounce and Learn: Modeling Scene Dynamics with Real-World Bounces</a>
  <br />Senthil Purushwalkam, Abhinav Gupta, Danny Kaufman, Bryan Russell
  <br />International Conference on Learning Representations (ICLR), 2019.
  <br /><a href="https://research.adobe.com/news/how-a-ball-bounces-teaching-a-computer-real-world-physics/">Adobe blog</a>
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://chenhsuanlin.bitbucket.io/photometric-mesh-optim/"><img src="thumbs/2019_multiview_thumb.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://chenhsuanlin.bitbucket.io/photometric-mesh-optim/">Photometric Mesh Optimization for Video-Aligned 3D Object Reconstruction</a>
  <br />Chen-Hsuan Lin, Oliver Wang, Bryan Russell, Eli Shechtman, Vladimir G. Kim, Matthew Fisher, Simon Lucey
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2019.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://berndhuber.github.io/bscript/"><img src="thumbs/2019_broll_thumb.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://berndhuber.github.io/bscript/">B-Script: Transcript-based B-roll Video Editing with Recommendations</a>
  <br />Bernd Huber, Hijung Valentina Shin, Bryan Russell, Oliver Wang, Gautham J. Mysore
  <br />ACM Conference on Human Factors in Computing Systems (CHI), 2019.
  <br /><a href="https://research.adobe.com/news/helping-vloggers-create-better-videos/">Adobe blog</a>
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://github.com/LisaAnne/TemporalLanguageRelease"><img src="thumbs/2018_temporal_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://github.com/LisaAnne/TemporalLanguageRelease">Localizing Moments in Video with Temporal Language</a>
  <br />Lisa Anne Hendricks, Oliver Wang, Eli Shechtman, Josef Sivic, Trevor Darrell, Bryan Russell
  <br />Conference on Empirical Methods in Natural Language Processing (EMNLP), 2018.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://www.di.ens.fr/willow/research/bodynet/"><img src="thumbs/2018_bodynet_thumb.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://www.di.ens.fr/willow/research/bodynet/">BodyNet: Volumetric Inference of 3D Human Body Shapes</a>
  <br />G&uuml;l Varol, Duygu Ceylan, Bryan Russell, Jimei Yang, Ersin Yumer, Ivan Laptev, Cordelia Schmid
  <br />European Conference on Computer Vision (ECCV), 2018.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://imagine.enpc.fr/~groueixt/3D-CODED/index.html"><img src="thumbs/2018_3dcoded_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://imagine.enpc.fr/~groueixt/3D-CODED/index.html">3D-CODED: 3D Correspondences by Deep Deformation</a>
  <br />Thibault Groueix, Matthew Fisher, Vladimir G. Kim, Bryan Russell, Mathieu Aubry
  <br />European Conference on Computer Vision (ECCV), 2018.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://imagine.enpc.fr/~groueixt/atlasnet/"><img src="thumbs/atlasnet_2018_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://imagine.enpc.fr/~groueixt/atlasnet/">AtlasNet: A Papier-M&acirc;ch&eacute; Approach to Learning 3D Surface Generation</a>
  <br />Thibault Groueix, Matthew Fisher, Vladimir G. Kim, Bryan Russell, Mathieu Aubry
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2018.
  <br /><a href="https://research.adobe.com/a-papier-mache-approach-to-learning-3d-surface-generation/">Adobe blog</a>
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://geometry.cs.ucl.ac.uk/projects/2017/edit-transfer/"><img src="thumbs/multpass-transfer_2017_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://geometry.cs.ucl.ac.uk/projects/2017/edit-transfer/">Transferring Image-Based Edits for Multi-Channel Compositing</a>
  <br />James W. Hennessey, Wilmot Li, Bryan Russell, Eli Shechtman, Niloy J. Mitra
  <br />ACM Transactions on Graphics (SIGGRAPH Asia), 2017.
  </td>
  </tr>

  <tr>
  <td>
  <a href="https://github.com/LisaAnne/LocalizingMoments"><img src="thumbs/didemo_2017_thumb.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://github.com/LisaAnne/LocalizingMoments">Localizing Moments in Video with Natural Language</a>
  <br />Lisa Anne Hendricks, Oliver Wang, Eli Shechtman, Josef Sivic, Trevor Darrell, Bryan Russell
  <br />International Conference on Computer Vision (ICCV), 2017.
  <br /><a href="https://research.adobe.com/search-for-great-moments-in-videos-with-natural-language/">Adobe blog</a>
  </td>
  </tr>


  <tr>
  <td>
  <a href="http://visimportance.csail.mit.edu"><img src="thumbs/importance_2017_thumb.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://visimportance.csail.mit.edu/">Learning Visual Importance for Graphic Designs and Data Visualizations</a>
  <br />Zoya Bylinskii, Nam Wook Kim, Peter O'Donovan, Sami Alsheikh, Spandan Madan, Hanspeter Pfister, Fredo Durand, Bryan Russell, Aaron Hertzmann
  <br />UIST, 2017.
  <br /><font color="red">Best paper honorable mention</font>
  </td>
  </tr>


  <tr>
  <td>
  <a href="https://rohitgirdhar.github.io/ActionVLAD/"><img src="thumbs/actionvlad_2017_thumb.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="https://rohitgirdhar.github.io/ActionVLAD/">ActionVLAD: Learning Spatio-temporal Aggregation for Action Classification</a>
  <br />Rohit Girdhar, Deva Ramanan, Abhinav Gupta, Josef Sivic, Bryan Russell
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2017.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://www.cs.cmu.edu/~aayushb/pixelNet/#"><img src="thumbs/pixelnet_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://www.cs.cmu.edu/~aayushb/pixelNet/#">PixelNet: Representation <i>of</i> the Pixels, <i>by</i> the Pixels, and <i>for</i> the Pixels</a>
  <br />Aayush Bansal, Xinlei Chen, Bryan Russell, Abhinav Gupta, Deva Ramanan
  <br />arXiv, 2017.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://www.cs.cmu.edu/~aayushb/marrRevisited"><img src="thumbs/marr_cvpr16_thumb.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://www.cs.cmu.edu/~aayushb/marrRevisited">Marr Revisited: 2D-3D Alignment via Surface Normal Prediction</a>
  <br />Aayush Bansal, Bryan C. Russell, Abhinav Gupta
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2016.
  </td>
  </tr>

  <tr>
  <td align="center">
  <a href="http://imagine.enpc.fr/~suzano-f/exemplar-cnn"><img src="thumbs/adaptation_cvpr16_thumb.jpg" style="width:14em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://imagine.enpc.fr/~suzano-f/exemplar-cnn">Deep Exemplar 2D-3D Detection by Adapting from Real to Rendered Views</a>
  <br />Francisco Massa, Bryan C. Russell, Mathieu Aubry
  <br />Conference on Computer Vision and Pattern Recognition (CVPR), 2016.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://imagine.enpc.fr/~aubrym/projects/features_analysis"><img src="thumbs/iccv2015_thumb.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://imagine.enpc.fr/~aubrym/projects/features_analysis">Understanding Deep Features with Computer-Generated Imagery</a>
  <br />Mathieu Aubry and Bryan C. Russell
  <br />IEEE International Conference on Computer Vision (ICCV), 2015.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://deep-tagging.cs.washington.edu"><img src="thumbs/wildtags2015_thumb.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://deep-tagging.cs.washington.edu">Deep Classifiers from Image Tags in the Wild</a>
  <br />Hamid Izadinia, Bryan C. Russell, Ali Farhadi, Matthew D. Hoffman, Aaron Hertzmann
  <br />Multimedia COMMONS, ACM Multimedia, 2015.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://grail.cs.washington.edu/projects/jigsaw3d/index.html"><img src="thumbs/jigsaw3d_thumb.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://grail.cs.washington.edu/projects/jigsaw3d/index.html">The 3D Jigsaw Puzzle: Mapping Large Indoor Spaces</a>
  <br />Ricardo Martin-Brualla, Yanling He, Bryan C. Russell, Steven M. Seitz
  <br />European Conference on Computer Vision (ECCV), 2014.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://www.di.ens.fr/willow/research/seeing3Dchairs/index.html"><img src="thumbs/chair_thumb.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://www.di.ens.fr/willow/research/seeing3Dchairs/index.html">Seeing 3D Chairs: Exemplar Part-based 2D-3D Alignment Using a Large Dataset of CAD Models</a>
  <br />Mathieu Aubry, Daniel Maturana, Alexei A. Efros, Bryan C. Russell, Josef Sivic
  <br />IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://www.di.ens.fr/willow/research/painting_to_3d"><img src="thumbs/hal_2013_thumb.png" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://www.di.ens.fr/willow/research/painting_to_3d">Painting-to-3D Model Alignment Via Discriminative Visual Elements</a>
  <br />Mathieu Aubry, Bryan C. Russell, Josef Sivic
  <br />ACM Transactions on Graphics (presented at SIGGRAPH 2014), Vol. 33, No. 2, 2014.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://grail.cs.washington.edu/projects/label3d"><img src="thumbs/siggraphasia2013.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://grail.cs.washington.edu/projects/label3d">3D Wikipedia: Using Online Text to Automatically Label and Navigate Reconstructed Geometry</a>
  <br />Bryan C. Russell, Ricardo Martin-Brualla, Daniel J. Butler, Steven M. Seitz, Luke Zettlemoyer
  <br />ACM Transactions on Graphics (SIGGRAPH Asia), Vol. 32, No. 6, 2013.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://vision.princeton.edu/projects/2012/SUNprimitive"><img src="thumbs/nips2012_thumb_v2.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://vision.princeton.edu/projects/2012/SUNprimitive">Localizing 3D Cuboids in Single-view Images</a>
  <br />Jianxiong Xiao, Bryan C. Russell, Antonio Torralba
  <br />Advances in Neural Information Processing Systems (NIPS), 2012.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://www.di.ens.fr/willow/research/paintingalignment"><img src="thumbs/3drr2011_thumb_v4.jpg" style="width:19em;" /></a>&nbsp;&nbsp;&nbsp;</td>
  <td>
  <a href="http://www.di.ens.fr/willow/research/paintingalignment">Automatic Alignment of Paintings and Photographs Depicting a 3D Scene</a>
  <br />Bryan C. Russell, Josef Sivic, Jean Ponce, H&eacute;l&egrave;ne Dessales
  <br />3rd International IEEE Workshop on 3D Representation for
  Recognition (3dRR-11), 
  <br />associated with ICCV 2011.
  </td>
  </tr>

  <tr>
  <td>
  <a href="projects/SceneComposites/index.html"><img src="thumbs/nips09_b.jpg" style="width:19em;" /></a></td>
  <td>
<a href="projects/SceneComposites/index.html">Segmenting Scenes by Matching Image Composites</a>
<br />Bryan C. Russell, Alexei A. Efros, Josef Sivic, William T. Freeman, Andrew Zisserman
<br />Advances in Neural Information Processing Systems (NIPS),
2009.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://labelme.csail.mit.edu/LabelMeVideo"><img src="thumbs/ICCV-LabelMeVideo_frames.jpg" style="height:6em;" /></a></td>
  <td>
 <a href="http://labelme.csail.mit.edu/LabelMeVideo">LabelMe video: Building a Video Database with Human Annotations</a>
<!-- <a href="papers/LabelMeVideo.pdf">LabelMe video: Building a Video Database with Human Annotations</a> -->
<br />Jenny Yuen, Bryan C. Russell, Ce Liu, Antonio Torralba
<br />IEEE International Conference on Computer Vision (ICCV),
2009. 
<!-- <br /><a href="http://labelme.csail.mit.edu/VideoLabelMe/VLMVideoCapturingOnline/uploadVideo.html">Video collection challenge</a> -->
<!-- (<a href="papers/LabelMeVideo.pdf">PDF</a> | <a href="http://labelme.csail.mit.edu/VideoLabelMe/VLMVideoCapturingOnline/uploadVideo.html">Video collection challenge</a>) -->
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://labelme.csail.mit.edu/Release3.0/browserTools/php/labelme3d_toolbox.php"><img src="thumbs/LabelMe3D_v02.jpg" style="width:19em;" /></a></td>
  <td>
  <a href="http://labelme.csail.mit.edu/Release3.0/browserTools/php/labelme3d_toolbox.php">LabelMe3D: Building a Database of 3D Scenes from User Annotations</a>
  <br />Bryan C. Russell and Antonio Torralba
  <br />IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR), 2009. 
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://labelme.csail.mit.edu"><img src="thumbs/labelme.jpg" style="height:6em;" /></a></td>
  <td>
  <a href="http://labelme.csail.mit.edu">LabelMe: A Database and Web-based Tool for Image Annotation</a>
  <br />Bryan C. Russell, Antonio Torralba, Kevin P. Murphy, William T. Freeman
  <br />International Journal of Computer Vision, 77(1-3):157-173,
  2008.
  </td>
  </tr>

  <tr>
  <td>
  <a href="projects/recognitionBySceneAlignment/index.html"><img src="thumbs/russell07.jpg" style="height:6em;" /></a></td>
  <td>
  <a href="projects/recognitionBySceneAlignment/index.html">Object Recognition by Scene Alignment</a>
  <br />Bryan C. Russell, Antonio Torralba, Ce Liu, Rob Fergus, William T. Freeman
  <br />Advances in Neural Information Processing Systems (NIPS),
  2007.
  </td>
  </tr>

  <tr>
  <td>
  <a href="projects/mult_seg_discovery/index.html"><img src="thumbs/russell06.jpg" style="height:6em;" /></a></td>
  <td>
  <a href="projects/mult_seg_discovery/index.html">Using Multiple Segmentations to Discover Objects and their Extent in Image Collections</a>
  <br />Bryan C. Russell, Alexei A. Efros, Josef Sivic, William T. Freeman, Andrew Zisserman
  <br />IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR), 2006.
  </td>
  </tr>

  <tr>
  <td>
  <a href="http://www.ri.cmu.edu/publication_view.html?pub_id=5237"><img src="thumbs/words_seg.jpg" style="height:6em;" /></a></td>
  <td>
  <a href="http://www.ri.cmu.edu/publication_view.html?pub_id=5237">Discovering Objects and their Location in Images</a>
  <br />Josef Sivic, Bryan C. Russell, Alexei A. Efros, Andrew Zisserman, William T. Freeman
  <br />International Conference on Computer Vision (ICCV), 2005.
  <br /><font color="red">Winner of the <a style="color:red" href="https://www.computer.org/web/tcpami/helmholtz-prize">Helmholtz "test-of-time" Prize</a> at ICCV 2017</font>
  </td>
  </tr>

  </table>

  </font>

  <b>Misc.</b>

  <ul>
    <li>
      CVPR 2013: <a href="https://www.intel-university-collaboration.net/cvpr2013-bottlenecks">Intel-sponsored panel discussion on computational bottlenecks in computer vision</a>
    </li>
    <li>
      Spring
      2012: <a href="http://www.cs.washington.edu/education/courses/cse590v/12sp/">CSE 590V: Computer vision seminar</a>
    </li>
    <li>
      Fall
      2011: <a href="http://www.cs.washington.edu/education/courses/cse590v/11au/">CSE
      590V: Computer vision seminar</a>
    </li>
  </ul>

  <br />

</div>  

</body>

</html>
